{
  "general": {

    "data_dir": {
      "value": "../../data/germeval18",
      "default": null,
      "desc": "The input data dir. Should contain the .tsv files (or other data files) for the task."
    },

    "output_dir": {
      "value": null,
      "default": "output",
      "desc": "The output directory where the model predictions and checkpoints will be written."
    },

    "cache_dir": {
      "value": null,
      "default": "",
      "desc": "Where do you want to store the pre-trained models downloaded from s3"
    },

    "max_seq_length": {
      "value": null,
      "default": 150,
      "desc": "The maximum total input sequence length after WordPiece tokenization. 128 was too short for some texts"
    },

    "do_train": {
      "value": true,
      "default": true,
      "desc": "Whether to run training."
    },

    "do_eval": {
      "value": true,
      "default": true,
      "desc": "Whether to run eval on the dev set."
    },

    "do_lower_case": {
      "value": null,
      "default": false,
      "desc": "Set this flag if you are using an uncased model."
    },

    "train_batch_size": {
      "value": 32,
      "default": 32,
      "desc": "Total batch size for training."
    },

    "learning_rate": {
      "value": null,
      "default": 2e-5,
      "desc": "The initial learning rate for Adam."
    },

    "num_train_epochs":  {
      "value": null,
      "default": 6.0,
      "desc": "Total number of training epochs to perform."
    },

    "warmup_proportion":  {
      "value": null,
      "default": 0.1,
      "desc": "Proportion of training to perform linear learning rate warmup for. E.g., 0.1 = 10%% of training."
    },

    "no_cuda":  {
      "value": false,
      "default": false,
      "desc": "Whether not to use CUDA when available."
    },

    "local_rank":  {
      "value": null,
      "default": -1,
      "desc": "local_rank for distributed training on gpus."
    },

    "seed":  {
      "value": null,
      "default": 42,
      "desc": "random seed for initialization"
    },

    "gradient_accumulation_steps":  {
      "value": null,
      "default": 1,
      "desc": "Number of updates steps to accumulate before performing a backward/update pass."
    },

    "fp16":  {
      "value": null,
      "default": false,
      "desc": "Loss scaling to improve fp16 numeric stability. Only used when fp16 set to True. 0 (default value): dynamic loss scaling. Positive power of 2: static loss scaling value."
    },

    "loss_scale":  {
      "value": null,
      "default": 0,
      "desc": "Loss scaling to improve fp16 numeric stability. Only used when fp16 set to True. 0 (default value): dynamic loss scaling. Positive power of 2: static loss scaling value."
    },

    "server_ip":  {
      "value": null,
      "default": "",
      "desc": "Can be used for distant debugging."
    },

    "server_port":  {
      "value": null,
      "default": "",
      "desc": "Can be used for distant debugging."
    },

    "eval_every":  {
      "value": 10,
      "default": 30,
      "desc": "Steps per training loop (batches) required for evaluation on dev set. Set to 0 when you do not want to do evaluation on dev set during training."
    },

    "eval_batch_size": {
      "value": 64,
      "default": 32,
      "desc": "Total batch size for eval."
    },

      "mlflow_url": {
      "value": "http://80.158.39.167:5000/",
      "default": null,
      "desc": "Mlflow server for tracking experiments (e.g. http://80.123.45.167:5000/)"
    },

      "mlflow_experiment": {
      "value": "tm_experiment",
      "default": null,
      "desc": "Experiment name used for mlflow"
    },

    "bert_model": {
      "value": "bert-base-cased-de-2b-end",
      "default": null,
      "desc": "Bert pre-trained model selected in the list: bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese."
    },

      "mlflow_run_name": {
      "value": "tm germeval coarse testing",
      "default": null,
      "desc": "Name of the particular run for mlflow"
    },
    "mlflow_nested":  {
      "value": true,
      "default": true,
      "desc": "Nesting mlflow experiemtns"
    }
  },

  "task": {
    "balance_classes":  {
      "value": true,
      "default": false,
      "desc": "Balance classes using weighted CrossEntropyLoss. Original train set from GermEval18 is skewed and the final evaluation is macro averaged."
    },

    "dev_size":  {
      "value": 0.1,
      "default": 0,
      "desc": "Split a dev set from the training set using dev_size as proportion."
    }
  }
}


