{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FARM\n",
    "\n",
    "Welcome to the FARM tutorial! This notebook will guide you through the many ways to interact with this repository so you will be able to train a range of NLP models and harvest the rewards.\n",
    "\n",
    "First, you will learn how to kick off an experiment with just a few lines of code and a config file.\n",
    "\n",
    "Then we will dive deeper into the various tools that will help your models flourish. We'll also guide you through the steps to tailor the code to your data and tasks.\n",
    "\n",
    "And finally, you will learn how to save, load and set up your models for inference so that you can share the fruits of your labour.\n",
    "\n",
    "Happy FARMing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Mode\n",
    "\n",
    "We refer to the processing of a particular dataset using a specific model as an Experiment. All the parameters of an Experiment can be found in a config file. By altering the fields in this file, you can choose what kind of task you want to do, point the model to the data source and define all the parameters needed for a successful run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory is /Users/deepset/deepset/farm\n"
     ]
    }
   ],
   "source": [
    "# Let's adjust the working directory so that it is the root of the repository\n",
    "# This should be run just once\n",
    "\n",
    "import os\n",
    "os.chdir('../')\n",
    "print(\"Current working directory is {}\".format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say something about Cuda GPU speedup?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Apex not installed. If you use distributed training with local rank != -1 apex must be installed.\n",
      "07/17/2019 19:25:28 - INFO - farm.utils -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False\n",
      "07/17/2019 19:25:28 - INFO - botocore.credentials -   Found credentials in shared credentials file: ~/.aws/credentials\n",
      "07/17/2019 19:25:28 - INFO - farm.modeling.tokenization -   loading vocabulary file s3://int-models-bert/bert-base-cased-de-2b-end/vocab.txt from cache at /Users/deepset/.cache/torch/farm/dbcdd76296532b59a97391ca2fb6d925db69c07b96088f816c4807e106cfa392.0d38f6c5b4c99fde3f12a423d4f9d37ab448d6458ce0788ac543b38ae8975572\n",
      "07/17/2019 19:25:29 - INFO - farm.data_handler.data_silo -   Loading train set from: data/gnad/train.csv\n",
      "07/17/2019 19:26:32 - INFO - farm.data_handler.processor -   *** Show 3 random examples ***\n",
      "07/17/2019 19:26:32 - INFO - farm.data_handler.processor -   *** Example ***\n",
      "ID: train-1824-0\n",
      "Clear Text: \n",
      " \tlabel: Etat\n",
      " \ttext: FPÖ bemüht nach Weichselbraun-Spitze gegen Stenzel den ORF-Publikumsrat – Für ORF \"spielerisch-ironischer Grundton\". Wien – Krönchen, Promis, Alles Walzer und ein Mini-Eklat – wie jedes Jahr verfolgte ein Millionenpublikum die ORF-Übertragung des Wiener Opernballs: 2,429 Millionen Zuschauer bzw. ein Drittel der TV-Bevölkerung verfolgten am Donnerstag den Opernball-Abend in ORF 2. Die Eröffnung um 21.40 Uhr sahen bis zu 1,562 Millionen, im Schnitt waren es 1,456 Millionen. Der Marktanteil betrug 54 Prozent – der STANDARD berichtete. Die heurige Opernball-Übertragung erzielte im Teletest die beste Publikums-Beurteilung seit der Erhebung dieser Daten in den 1990er-Jahren. Daran änderte auch ein Mini-Eklat um Moderatorin Mirjam Weichselbraun nichts. Einen Einspieler mit Opernball-Aufnahmen aus den 1980er-Jahren, in dem die damalige ORF-Moderatorin und heutige FPÖ-Politikerin Ursula Stenzel den Sänger Harald Serafin interviewt hatte, kommentierte Weichselbraun mit einer Spitze gegen die Ex-Kollegin: Ich frage mich, was aus der Interviewerin geworden ist. Wahrscheinlich nicht viel. Die Szene des Anstoßes – auf Youtube gestellt von FPÖ-TV Weichselbraun zog damit den Ärger der FPÖ auf sich, und die Freiheitlichen wollen die Opernball-Übertragung nun zum Thema im ORF-Publikumsrat machen. Von einer skandalösen Entgleisung sprach FPÖ-Generalsekretär Herbert Kickl am Freitag. Es stehe der Moderatorin eines öffentlich-rechtlichen Senders nicht zu, vor laufender Kamera und einem Millionenpublikum eine derart abfällige Bemerkung über Dritte zu machen, in diesem Fall über eine hochverdiente langjährige ZiB-Moderatorin, höchst erfolgreiche Politikerin und Landtagsabgeordnete der FPÖ Wien, meinte Kickl. Das steht in krassem Widerspruch zum öffentlich-rechtlichen Auftrag des ORF. Die FPÖ werde der Frage nachgehen, ob es sich um eine spontane Eingebung Weichselbrauns gehandelt habe, denn. Der Verdacht liegt nahe, dass es ein abgekartetes Spiel war und ein früheres Interview Ursula Stenzels mit Harald Serafin nur deshalb eingespielt wurde, um Weichselbraun Gelegenheit für ihre wohlvorbereitete Diffamierung zu bieten, so Kickl. Dort war man unterdessen um Beruhigung bemüht. Trademark der ORF-Moderationen beim Opernball ist ein spielerisch-ironischer Grundton, der dem gesellschaftlichen Höhepunkt des Faschings angemessen ist. Wenn dann im Laufe einer dreistündigen TV-Live-Übertragung bei aller Professionalität eine Pointe einmal nicht richtig aufgeht oder missverständlich ankommt, ist das bedauerlich und selbstverständlich nicht beabsichtigt, erklärte TV-Unterhaltungschef Edgar Böhm gegenüber der APA. Same procedure as every year hieß es unterdessen bei den Lugners. Laut dem Privatsender ATV kam es zwischen Opernball-Gottseibeiuns! Richard Lugner und Frau Cathy in der Ballnacht zum Streit. Die beiden fuhren getrennt nach Hause. Frau Lugner soll sich zu intensiv um ihren Gast Mr. Probz gekümmert haben, unschöne Streitszenen und heftige Wortgefechte waren die Folge. Ob es dieses Mal zur Scheidung reicht oder es sich nur um eine quotenbedingte Inszenierung handelt, zeigt der Sender am Freitag um 19.35 Uhr in seiner Doku-Soap Mörtel am Opernball 2016: Stress am Ball.\n",
      "Features: \n",
      " \tinput_ids: [3, 64, 13944, 14897, 188, 19537, 618, 14381, 243, 6772, 383, 21155, 842, 86, 26375, 243, 20359, 567, 2, 864, 26375, 151, 1422, 20333, 28, 243, 25492, 532, 565, 4429, 151, 4813, 2319, 2, 24347, 280, 2036, 5913, 82, 2036, 10795, 4527, 1287, 42, 39, 14156, 243, 19793, 15677, 2, 246, 5213, 203, 16364, 39, 1483, 26920, 1771, 107, 30, 26375, 243, 9362, 91, 5596, 10030, 1152, 26902, 5982, 99, 2036, 6613, 26942, 1483, 6160, 1372, 4813, 39, 7186, 21, 4332, 243, 2492, 17483, 235, 4632, 86, 10030, 1152, 243, 4253, 50, 26375, 99, 4813, 125, 7972, 259, 2439, 4813, 2495, 1971, 13316, 255, 81, 62, 2036, 8938, 26933, 1483, 2036, 106, 8259, 636, 229, 62, 2036, 4242, 26960, 1483, 4813, 233, 22858, 5810, 8794, 1028, 2, 21, 24, 10080, 26947, 6291, 26938, 26926, 6537, 4813, 125, 5726, 17024, 22, 10030, 1152, 243, 9362, 5614, 106, 3584, 3331, 30, 4078, 20359, 243, 5358, 602, 21, 8151, 534, 2735, 50, 86, 2711, 6, 243, 605, 4813, 15047, 12133, 194, 39, 14156, 243, 19793, 15677, 259, 19093, 14, 9899, 3171, 26911, 19537, 618, 14381, 2013, 4813, 6038, 18865, 1823, 6, 114, 10030, 1152, 243, 9450, 147, 86, 3486, 6, 243, 605, 2036, 50, 128, 30, 8640, 26375, 243, 19093, 14, 42, 6715, 64, 13944, 243, 22662, 17790, 21155, 842, 86, 5166, 16039, 1723, 1593, 14, 2556, 4892, 26901, 466, 2036, 24521, 19537, 618, 14381, 114, 225, 6772, 383, 30, 1108, 243, 19523, 14, 5982, 1671, 10160, 26897, 3277, 2036, 961, 147, 21, 6405, 1066, 2750, 127, 4813, 4]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabel_ids: 7\n",
      "07/17/2019 19:26:32 - INFO - farm.data_handler.processor -   *** Example ***\n",
      "ID: train-4506-0\n",
      "Clear Text: \n",
      " \tlabel: Panorama\n",
      " \ttext: Zweite Wochenhälfte wieder mit Temperaturen jenseits der 30 Grad. Wien – Die Abkühlung war nur eine vorübergehende. Laut Prognose der Zentralanstalt für Meteorologie und Geodynamik (ZAMG) gilt es in den kommenden Tagen zwar noch eine Kaltfront zu durchtauchen, dann meldet sich aber der Sommer zurück. Für die zweite Wochenhälfte sind wieder Temperaturen über 30 Grad angesagt. Die Details: Am Montag überwiegt nördlich des Alpenhauptkammes in den Landesteilen östlich von Salzburg sowie generell am Alpenostrand und im Grazer Becken meist sonniges und trockenes Wetter. Nur vereinzelt zieren ein paar dichtere Wolken den Himmel, die jedoch harmlos bleiben. Im Westen und Süden wechseln kurze sonnige Phasen mit deutlich mehr Wolken. Während es in Osttirol bereits am Vormittag häufig regnet, setzt der Regen sonst erst im Laufe des Nachmittags ein. Der Wind weht schwach bis mäßig, am Alpenostrand und an der föhnigen Alpennordseite lebhaft bis kräftig aus Ost bis Südwest. Die Frühtemperaturen liegen zwischen neun und 18 Grad, die Nachmittagstemperaturen zwischen 23 und 32 Grad, im Südwesten bleibt es kühler mit 18 bis 22 Grad. Am Dienstag hängen bis Mittag im ganzen Land dichte Wolken am Himmel, aus denen häufig Regenschauer niedergehen. Den meisten Niederschlag gibt es südlich des Alpenhauptkammes. In der Folge beginnt jedoch die Wolkendecke aufzulockern und die sonnigen Abschnitte nehmen zu. Am längsten trüb mit Schauern bleibt es in Osttirol und Kärnten. Der Wind kommt schwach bis mäßig, im Osten anfangs lebhaft aus West bis Nord. Die Tiefsttemperaturen betragen elf bis 19 Grad, die Tageshöchsttemperaturen 18 bis 25 Grad. Am Mittwoch startet der Tag stellenweise mit etwas Nebel. Tagsüber scheint aber verbreitet die Sonne und es ziehen meist nur hohe, dünne Schleierwolken über den Himmel. Stärkere Quellwolkenbildung gibt es nur entlang des Alpenhauptkammes und im Südwesten. Hier sind lokale Regenschauer nicht auszuschließen. Der Wind weht generell nur schwach. Die Frühwerte liegen bei acht bis 15 Grad, sie steigen tagsüber auf 21 bis 28 Grad. Viel Sonne sollte es am Donnerstag geben. Zwar ziehen von Westen her im Tagesverlauf einige hohe, dünne Wolkenfelder auf. Diese können den sonnigen Eindruck aber nicht trüben. Der Wind weht schwach bis mäßig aus Südost bis Süd. Von zehn bis Grad in der Früh steigen die Temperaturen auf 26 bis 31 Grad. Auch am Freitag scheint die Sonne in weiten Teilen des Landes nahezu ungetrübt, Quellwolken gibt es nur wenige über dem Alpenhauptkamm. In der Osthälfte ziehen zeitweise noch ein paar hohe Schleierwolken über den Himmel. Der Wind weht schwach bis mäßig aus Südost bis Süd. Die Frühtemperaturen liegen bei elf bis 18 Grad, die Höchsttemperaturen bei 26 bis 33 Grad.\n",
      "Features: \n",
      " \tinput_ids: [3, 15335, 2124, 17451, 525, 114, 14037, 14751, 21, 1144, 6327, 4813, 2319, 2, 125, 14423, 2305, 27, 185, 356, 155, 8608, 26897, 4813, 5126, 11397, 21, 5832, 2816, 142, 21278, 1864, 42, 241, 13606, 4556, 172, 123, 122, 26924, 13898, 5133, 1626, 229, 50, 86, 5649, 3499, 1616, 357, 155, 23708, 8025, 81, 261, 13248, 280, 2036, 670, 23932, 144, 386, 21, 2213, 705, 4813, 864, 30, 2961, 2124, 17451, 287, 525, 14037, 204, 1144, 6327, 3452, 1063, 4813, 125, 10834, 5982, 570, 4141, 10005, 202, 4879, 91, 8913, 2063, 25491, 16, 50, 86, 1168, 6598, 5841, 88, 11054, 545, 11306, 235, 8913, 1268, 2741, 42, 106, 14042, 6, 12764, 2734, 20157, 1865, 42, 10740, 16, 7155, 4813, 3459, 19579, 2892, 444, 39, 4895, 12061, 1031, 17917, 86, 8307, 2036, 30, 742, 24395, 520, 3143, 4813, 346, 3243, 42, 3236, 9042, 7478, 20157, 288, 18669, 114, 2173, 380, 17917, 4813, 1939, 229, 50, 2161, 15698, 777, 235, 24390, 3346, 2692, 604, 2036, 3784, 21, 4585, 3096, 624, 106, 6156, 91, 13143, 26902, 39, 4813, 233, 3995, 12412, 333, 14425, 255, 20786, 80, 2036, 235, 8913, 1268, 2741, 42, 104, 21, 69, 3183, 219, 8913, 15901, 3337, 26436, 1727, 255, 17776, 147, 2161, 255, 13389, 4813, 125, 4118, 14663, 7, 2598, 597, 3340, 42, 339, 6327, 2036, 30, 13143, 14660, 5288, 7, 597, 1493, 42, 3745, 6327, 2036, 106, 7810, 3141, 229, 23249, 6, 114, 339, 255, 1389, 6327, 4813, 570, 4674, 14007, 255, 16341, 106, 6109, 414, 12061, 26897, 17917, 235, 8307, 2036, 147, 4]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabel_ids: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/17/2019 19:26:32 - INFO - farm.data_handler.processor -   *** Example ***\n",
      "ID: train-3657-0\n",
      "Clear Text: \n",
      " \tlabel: Panorama\n",
      " \ttext: Zuvor war von zwei Getöteten berichtet worden – Nun wurden sechs weitere Leichen identifiziert. Mexiko-Stadt – Nach dem versehentlichen Beschuss einer Touristengruppe durch ägyptische Sicherheitskräfte ist die Zahl der dabei getöteten Mexikaner auf acht gestiegen. Das mexikanische Außenministerium erklärte am Dienstag, sechs weitere Leichen seien von Diplomaten vor Ort identifiziert worden. Zuvor war von zwei getöteten, sechs verletzten und sechs noch vermissten Landsleuten die Rede gewesen. Ägyptische Polizisten und Soldaten hatten am Sonntag bei der Verfolgung von islamistischen Kämpfern im Westen des Landes versehentlich einen Konvoi von mexikanischen Touristen beschossen, die in ägyptischer Begleitung waren. Insgesamt befanden sich 14 Mexikaner in der Touristengruppe. Die sechs bei dem Vorfall Verletzten wurden am Dienstag weiter im Krankenhaus behandelt, waren aber nicht in Lebensgefahr. Bei dem Beschuss waren nach Angaben der ägyptischen Behörden insgesamt zwölf Menschen getötet worden. Die mexikanische Außenministerin Claudia Ruiz Massieu reiste am Dienstag nach Kairo. Sie wollte sich dort mit Regierungsvertretern treffen, um Antworten zu den Hintergründen des Vorfalls zu erhalten. Begleitet wurde sie von Angehörigen der mexikanischen Todesopfer.\n",
      "Features: \n",
      " \tinput_ids: [3, 9198, 185, 88, 382, 6090, 6418, 7, 3900, 671, 2, 4692, 468, 1938, 1344, 16569, 17984, 4813, 8766, 243, 560, 2, 326, 128, 7607, 5323, 549, 308, 225, 10736, 2390, 261, 16155, 262, 3503, 4520, 127, 30, 1411, 21, 1340, 7235, 7, 6760, 5548, 115, 2531, 10228, 4813, 295, 14759, 9202, 10392, 660, 4259, 235, 4674, 2036, 1938, 1344, 16569, 1196, 88, 22627, 200, 874, 17984, 671, 4813, 9198, 185, 88, 382, 7235, 7, 2036, 1938, 23088, 42, 1938, 357, 25918, 7, 11514, 15806, 30, 4468, 1396, 4813, 9521, 15099, 1065, 8166, 42, 4200, 1520, 235, 3030, 178, 21, 8930, 88, 8864, 2370, 18772, 26898, 106, 3243, 91, 1168, 7607, 2395, 303, 438, 4723, 26899, 88, 22354, 10736, 824, 3309, 2036, 30, 50, 16155, 532, 19861, 636, 4813, 5141, 10840, 144, 835, 6760, 5548, 50, 21, 10736, 2390, 4813, 125, 1938, 178, 128, 15776, 21815, 468, 235, 4674, 424, 106, 4870, 7107, 2036, 636, 386, 149, 50, 1427, 10341, 4813, 467, 128, 549, 308, 636, 188, 2428, 21, 23716, 4708, 2021, 4420, 1075, 7235, 671, 4813, 125, 14759, 9202, 10392, 14, 17594, 2128, 366, 6818, 15344, 12228, 235, 4674, 188, 20501, 4813, 371, 2664, 144, 896, 114, 3693, 7932, 26898, 4499, 2036, 259, 16486, 81, 86, 2484, 7377, 91, 15776, 26902, 81, 1893, 4813, 17071, 75, 192, 213, 88, 11679, 21, 22354, 5652, 14170, 4813, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabel_ids: 3\n",
      "07/17/2019 19:26:32 - INFO - farm.data_handler.data_silo -   Loading dev set as a slice of train set\n",
      "07/17/2019 19:26:32 - INFO - farm.data_handler.data_silo -   Took 924 samples out of train set to create dev set (dev split = 0.1)\n",
      "07/17/2019 19:26:32 - INFO - farm.data_handler.data_silo -   Loading test set from: data/gnad/test.csv\n",
      "07/17/2019 19:26:39 - INFO - farm.data_handler.processor -   *** Show 3 random examples ***\n",
      "07/17/2019 19:26:39 - INFO - farm.data_handler.processor -   *** Example ***\n",
      "ID: test-209-0\n",
      "Clear Text: \n",
      " \tlabel: Wirtschaft\n",
      " \ttext: Finanzminister erinnert an Unumkehrbarkeit von Währungsunion. Athen – Eine Rückkehr vom Euro zur Drachme würde Griechenland nach Angaben von  Finanzminister Giannis Varoufakis auch vor äußerst praktische Probleme stellen.  Wir haben die Notenpressen zerstört, sagte Varoufakis am Donnerstag im  australischen Radiosender ABC. Im Jahr 2000, ein Jahr vor der Einführung des Euro, war nach seinen Worten  eines der ersten Dinge, die wir tun mussten, alle unsere Notenpressen  loszuwerden – als Teil einer Beteuerung, dass diese Währungsunion unumkehrbar  ist. Zum Drucken der Drachme habe Griechenland somit keine Kapazitäten mehr. Angesichts der festgefahrenen Lage im Schuldenstreit zwischen Griechenland  und seinen internationalen Gläubigern wird über ein Ausscheiden des Landes aus  der Eurozone spekuliert. Am Sonntag will die griechische Regierung die  Bevölkerung in einem Referendum über die Forderungen der Gläubiger abstimmen  lassen. Sie wirbt dabei massiv für ein Nein zu den Vorschlägen.\n",
      "Features: \n",
      " \tinput_ids: [3, 13330, 6446, 104, 234, 107, 801, 3082, 88, 13420, 6219, 4813, 8753, 2, 917, 5268, 275, 918, 252, 6582, 8, 373, 1903, 7119, 188, 2428, 88, 13330, 3945, 13408, 26902, 4975, 1504, 8716, 4824, 26902, 194, 200, 10527, 19051, 5034, 3392, 4813, 655, 474, 30, 10277, 17195, 26898, 6192, 2036, 1267, 4975, 1504, 8716, 4824, 26902, 235, 4632, 106, 13933, 6439, 8198, 23954, 26958, 4813, 346, 203, 2271, 2036, 39, 203, 200, 21, 6165, 91, 918, 2036, 185, 188, 800, 8602, 443, 21, 781, 7760, 2036, 30, 232, 4013, 4657, 2036, 987, 6712, 10277, 17195, 26898, 7066, 271, 5420, 2, 153, 717, 225, 483, 2607, 27, 2036, 221, 620, 13420, 6219, 24378, 801, 351, 127, 4813, 2147, 3548, 7, 21, 6582, 8, 373, 555, 7119, 3361, 668, 12989, 380, 4813, 10063, 21, 5772, 775, 7, 2885, 106, 8447, 4072, 597, 7119, 42, 800, 4178, 10048, 26898, 292, 204, 39, 13232, 91, 1168, 147, 21, 918, 7407, 23816, 321, 4813, 570, 3030, 1279, 30, 14166, 2154, 30, 2492, 50, 297, 23327, 204, 30, 8870, 21, 10048, 19752, 21258, 160, 1641, 4813, 371, 25956, 1340, 15732, 142, 39, 12290, 81, 86, 16405, 26898, 4813, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabel_ids: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/17/2019 19:26:39 - INFO - farm.data_handler.processor -   *** Example ***\n",
      "ID: test-864-0\n",
      "Clear Text: \n",
      " \tlabel: Inland\n",
      " \ttext: Wahl der neuen Landesregierung unter ÖVP-Chef Hermann Schützenhofer. Graz - Am Dienstag trat der neue steiermärkische Landtag zur konstituierenden Sitzung zusammen, um die neue Landesregierung und die Landtagspräsidenten zu wählen. Der scheidende Landeshauptmann Franz Voves (SPÖ) war nicht anwesend, dafür die früheren Landeschefs Josef Krainer und Waltraud Klasnic (beide ÖVP). Bei der Wahl der Landtagspräsidenten gab es keine Einstimmigkeit. Die Grünen verweigerten FPÖ-Chef Gerhard Kurzmann ihre Zustimmung zur Wahl zum Dritten Präsidenten: Wer einen derartig hetzerischen Wahlkampf gegen Minderheiten und Asylsuchende mitzuverantworten habe, dürfe dieses Amt nicht innehaben, so Grün-Abgeordneter Lambert Schönleitner. Die KPÖ erteilte nicht nur Kurzmann, sondern auch der Ersten Landtagspräsidentin Bettina Vollath eine Absage. Begründung des Landtagsabgeordneten Werner Murgg: Es ist keine gute Sitte, jemand zur Präsidentin zu machen, die diesem Landtag nie angehört hat. Manuela Khom (ÖVP) wähle man selbstverständlich, sie habe diesem Hause angehört. Beim dritten Präsidenten gehe man traditionell nicht mit, das Amt solle man abschaffen. Der Grüne Abgeordnete Lambert Schönleitner erklärte: Wir wählen Vollath mit, sie war stets sehr offen in Richtung Opposition, z. B. beim Haushaltsrecht. Selbiges gelte für Manuela Khom (ÖVP). Persönlich habe er nichts gegen Gerhard Kurzmann, man wähle ihn wegen der Politik der FPÖ nicht mit, die Partei habe einen sehr problematischen Wahlkampf geführt, z. B. auf Plakaten Wohnungsbau und Moscheen gegeneinander ausgespielt. Im neuen steirischen Landtag sitzen 15 Abgeordnete der SPÖ, je 14 der ÖVP und Freiheitlichen sowie drei Grüne und zwei Kommunisten. Erstmals war die  Sitzung am Dienstag von Gebärdendolmetscherinnen begleitet. Innerhalb der nächsten eineinhalb Jahre solle es ein nachfrageorientiertes Angebot in dieser Hinsicht geben, hieß es.\n",
      "Features: \n",
      " \tinput_ids: [3, 1401, 21, 1280, 13791, 267, 26318, 243, 3913, 5769, 15393, 8838, 4813, 14042, 243, 570, 4674, 2415, 21, 1234, 3809, 97, 8239, 4824, 1065, 4306, 252, 494, 12678, 3471, 9470, 1037, 2036, 259, 30, 1234, 13791, 42, 30, 16417, 8210, 81, 11900, 4813, 233, 20736, 57, 1168, 26748, 2748, 4087, 10587, 123, 26336, 5133, 185, 149, 20321, 2036, 1760, 30, 4263, 1168, 8386, 26902, 6111, 5795, 1506, 42, 14599, 6118, 26904, 5993, 26902, 14314, 26909, 123, 3296, 26318, 5133, 4813, 467, 21, 1401, 21, 16417, 8210, 1301, 229, 668, 18865, 21258, 25717, 26908, 359, 4813, 125, 5373, 26792, 26898, 64, 13944, 243, 3913, 8003, 3656, 749, 682, 6990, 252, 1401, 260, 8731, 4978, 5982, 1309, 303, 5057, 80, 5726, 15065, 4368, 8966, 383, 19611, 42, 26272, 2455, 57, 114, 271, 12315, 7, 555, 2036, 10555, 1328, 1269, 149, 18332, 5305, 2036, 181, 1040, 243, 10847, 11474, 1429, 5510, 6909, 344, 4813, 125, 58, 13944, 13635, 149, 356, 3656, 749, 2036, 967, 194, 21, 4355, 16417, 4983, 14, 9094, 1368, 2302, 2497, 155, 26788, 4813, 3113, 91, 16417, 228, 11305, 7379, 7532, 12436, 5982, 482, 127, 668, 4493, 15020, 2636, 26897, 2036, 8026, 252, 20661, 81, 1788, 2036, 30, 798, 4306, 1580, 15503, 193, 4813, 15675, 26903, 58, 23855, 123, 26318, 5133, 25, 22623, 478, 782, 11810, 2036, 213, 555, 798, 5956, 15503, 4813, 3793, 3831, 4978, 7220, 478, 13026, 149, 114, 2036, 93, 1269, 5988, 478, 15748, 1886, 4813, 233, 14134, 13492, 11474, 1429, 5510, 6909, 344, 4259, 5982, 655, 11900, 2302, 2497, 114, 4]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabel_ids: 8\n",
      "07/17/2019 19:26:39 - INFO - farm.data_handler.processor -   *** Example ***\n",
      "ID: test-61-0\n",
      "Clear Text: \n",
      " \tlabel: Web\n",
      " \ttext: Name des Nachfolgers von \"sanft & sorgfältig\" wird noch nicht verraten, auch nichts zu den Inhalten. Jan Böhmermann und Olli Schulz starten an diesem Sonntag bei Spotify. Nur drei Tage, nachdem Böhmermanns TV-Show Neo Magazin Royal bei ZDFneo am Donnerstag, 12. Mai, wieder zu sehen ist, soll das erste neue Podcast des Duos zu hören sein. Das teilte der Streamingdienst am Montag in seinem Blog mit. Zum Namen der neuen Show nach dem Ende der bisherigen Show sanft & sorgfältig hieß es lapidar: Das dürfen wir Euch noch nicht verraten. Auch zu Inhalten sei noch nichts mitzuteilen, sagte eine Sprecherin. Spotify ist weltweiter Marktführer unter den Streamingdiensten. Beim Streaming werden Musikstücke oder andere Audiobeiträge direkt aus dem Netz abgespielt. Olli Schulz und Jan Böhmermann hatten ihre Sonntagsshow sanft & sorgfältig beim RBB-Sender Radioeins. Ende April hatte das Duo angekündigt, sanft & sorgfältig nicht fortsetzen zu wollen. Spotify spielt mit dem Namen der bisherigen Show und präsentiert auf seinem Blog eine Reihe von Plakaten, die für den neuen Podcast werben sollen: Abgefuckt & Anspruchslos etwa gab es schon länger, Maskulin & Mariniert, Potent & Preisgekrönt sowie Vegan & Verschmust sind neu hinzugekommen.\n",
      "Features: \n",
      " \tinput_ids: [3, 3504, 91, 4076, 26902, 88, 151, 8485, 136, 2461, 24222, 151, 292, 357, 149, 21880, 2036, 194, 2013, 81, 86, 13940, 26898, 4813, 4802, 22695, 6, 749, 42, 1624, 3299, 12476, 13179, 104, 798, 3030, 178, 276, 237, 778, 26951, 4813, 3459, 678, 2908, 2036, 3135, 22695, 6, 7099, 4332, 243, 7491, 929, 26910, 11263, 8783, 178, 9168, 175, 26910, 235, 4632, 2036, 810, 4813, 1200, 2036, 525, 81, 2265, 127, 2036, 459, 93, 1139, 1234, 11024, 17004, 91, 18506, 26902, 81, 7734, 167, 4813, 295, 5751, 21, 2218, 24742, 2068, 235, 4141, 50, 813, 17812, 114, 4813, 2147, 1646, 21, 1280, 7491, 188, 128, 926, 21, 4670, 7491, 8485, 136, 2461, 24222, 5453, 229, 2094, 26920, 11372, 5982, 295, 4030, 232, 8408, 8, 357, 149, 21880, 4813, 831, 81, 13940, 26898, 350, 357, 2013, 114, 23257, 2036, 1267, 155, 14267, 4813, 276, 237, 778, 26951, 127, 26240, 26900, 2131, 2320, 267, 86, 2218, 24742, 21290, 4813, 3793, 2218, 24742, 266, 1534, 7946, 309, 1355, 15081, 2311, 14320, 3570, 147, 128, 3552, 10325, 1823, 26901, 4813, 1624, 3299, 12476, 42, 4802, 22695, 6, 749, 1520, 682, 7148, 25138, 8485, 136, 2461, 24222, 785, 19672, 26925, 243, 8311, 6439, 1276, 4813, 926, 1331, 466, 93, 18506, 8898, 2036, 8485, 136, 2461, 24222, 149, 22638, 81, 2376, 4813, 276, 237, 778, 26951, 3727, 114, 128, 1646, 21, 4670, 7491, 42, 9998, 115, 813, 17812, 155, 4046, 88, 23589, 457, 2036, 30, 142, 86, 1280, 11024, 17004, 20674, 1922, 5982, 226, 2289, 4155, 26901, 2461, 9053, 520, 4]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabel_ids: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/17/2019 19:26:39 - INFO - farm.data_handler.data_silo -   Examples in train: 8320\n",
      "07/17/2019 19:26:39 - INFO - farm.data_handler.data_silo -   Examples in dev  : 924\n",
      "07/17/2019 19:26:39 - INFO - farm.data_handler.data_silo -   Examples in test : 1027\n",
      "07/17/2019 19:26:40 - INFO - farm.data_handler.data_silo -   Using class weights: [0.6733025815327345, 0.9394760614272809, 0.7602339181286549, 0.6878306878306878, 1.966903073286052, 0.8080808080808081, 2.154882154882155, 1.7247097844112769, 1.121898597626753]\n",
      "07/17/2019 19:26:40 - INFO - farm.modeling.language_model -   loading archive file s3://int-models-bert/bert-base-cased-de-2b-end/bert-base-cased-de-2b-end.tar.gz from cache at /Users/deepset/.cache/torch/farm/9c04dc7fe652b18e117a3bcfbbd50a46dd97dcce1b27f4689c47c52fbf0ebf77.5d8643be67c1cdea6a3daad77fcc21f22aaca376cc4bffa9152d4260c4285410\n",
      "07/17/2019 19:26:40 - INFO - farm.modeling.language_model -   extracting archive file /Users/deepset/.cache/torch/farm/9c04dc7fe652b18e117a3bcfbbd50a46dd97dcce1b27f4689c47c52fbf0ebf77.5d8643be67c1cdea6a3daad77fcc21f22aaca376cc4bffa9152d4260c4285410 to temp dir /var/folders/9y/kg7mpp0947l5n87j11ff64200000gp/T/tmpg7k2dcnv\n",
      "07/17/2019 19:26:45 - INFO - farm.modeling.language_model -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "07/17/2019 19:26:47 - INFO - farm.modeling.language_model -   Automatically detected language from language model name: german\n",
      "07/17/2019 19:26:47 - INFO - farm.train -   ***** Running training *****\n",
      "Train epoch 1/2:   0%|          | 2/1040 [00:31<4:32:11, 15.73s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2cc8cdd6a7d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mconf_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"experiments/text_classification/gnad_config.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/deepset/farm/farm/experiment.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    105\u001b[0m     )\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"save/{args.name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deepset/farm/farm/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0mper_sample_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits_to_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_propagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mper_sample_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# Perform  evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deepset/farm/farm/train.py\u001b[0m in \u001b[0;36mbackward_propagate\u001b[0;34m(self, loss, step)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_acc_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deepset/environments/main3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deepset/environments/main3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from farm.experiment import run_experiment\n",
    "from farm.file_utils import read_config, unnestConfig\n",
    "\n",
    "\n",
    "# Can we just pass conf file to run experiment?\n",
    "# How do I talk about what's in the config file in this tutorial?\n",
    "conf_file = \"experiments/text_classification/gnad_config.json\"\n",
    "args = read_config(conf_file, flattend=True)\n",
    "run_experiment(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You just trained a text classification model! But maybe you want to tweak some parameters to improve the model. For this, you'll want to look into the config file we defined above. You might want to tweak the learning rate, batch size or the number of epochs.\n",
    "\n",
    "With the default settings we managed to get X\n",
    "\n",
    "See if you can beat this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Major Components (?)\n",
    "\n",
    "So how does this all work under the hood? In the same directory as this notebook you will find a set of deconstructed examples which can be run as they are and highlight the main objects that handle the different aspects of cultivating a machine learning model. Below, you will find each element needed to run the same document classification task as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from farm.modeling.tokenization import BertTokenizer\n",
    "from farm.data_handler.processor import GNADProcessor\n",
    "from farm.data_handler.data_silo import DataSilo\n",
    "from farm.modeling.language_model import Bert\n",
    "from farm.modeling.prediction_head import TextClassificationHead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to fetch a device to support gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we initialize a tokenizer that will be used for preprocessing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/17/2019 17:54:39 - INFO - farm.modeling.tokenization -   loading vocabulary file s3://int-models-bert/bert-base-cased-de-2b-end/vocab.txt from cache at /Users/deepset/.cache/torch/farm/dbcdd76296532b59a97391ca2fb6d925db69c07b96088f816c4807e106cfa392.0d38f6c5b4c99fde3f12a423d4f9d37ab448d6458ce0788ac543b38ae8975572\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"bert-base-german-cased\",\n",
    "    do_lower_case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the BERT Tokenizer which uses the byte pair encoding method. It is loaded with the German model. We can test out how it will do on an example sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Th',\n",
       " '##is',\n",
       " 'is',\n",
       " 'a',\n",
       " 'sen',\n",
       " '##ten',\n",
       " '##ce',\n",
       " 'that',\n",
       " 'will',\n",
       " 'serv',\n",
       " '##e',\n",
       " 'as',\n",
       " 'o',\n",
       " '##ur',\n",
       " 'ex',\n",
       " '##amp',\n",
       " '##le']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_sentence = \"This is a sentence that will serve as our example\"\n",
    "tokenizer.tokenize(example_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to prepare the data for the model, we need a set of functions to transform data contained in files into PyTorch Dataset objects. These are contained within Processor objects which are specific to each dataset. The abstract class can be found in farm.data_handling.processor.Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = GNADProcessor(tokenizer=tokenizer,\n",
    "                          max_seq_len=128,\n",
    "                          data_dir=\"../data/gnad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions of the processor are called by the DataSilo object which stores the data and enforces the train, dev, test split and contains statistics about the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/17/2019 18:14:19 - INFO - farm.data_handler.data_silo -   Loading train set from: ../data/gnad/train.csv\n",
      "07/17/2019 18:14:19 - INFO - farm.data_handler.utils -   downloading and extracting file gnad to dir /Users/deepset/deepset/data\n",
      "100%|██████████| 10753295/10753295 [00:00<00:00, 27661712.52B/s]\n",
      "07/17/2019 18:15:27 - INFO - farm.data_handler.processor -   *** Show 3 random examples ***\n",
      "07/17/2019 18:15:27 - INFO - farm.data_handler.processor -   *** Example ***\n",
      "ID: train-1824-0\n",
      "Clear Text: \n",
      " \tlabel: Etat\n",
      " \ttext: FPÖ bemüht nach Weichselbraun-Spitze gegen Stenzel den ORF-Publikumsrat – Für ORF \"spielerisch-ironischer Grundton\". Wien – Krönchen, Promis, Alles Walzer und ein Mini-Eklat – wie jedes Jahr verfolgte ein Millionenpublikum die ORF-Übertragung des Wiener Opernballs: 2,429 Millionen Zuschauer bzw. ein Drittel der TV-Bevölkerung verfolgten am Donnerstag den Opernball-Abend in ORF 2. Die Eröffnung um 21.40 Uhr sahen bis zu 1,562 Millionen, im Schnitt waren es 1,456 Millionen. Der Marktanteil betrug 54 Prozent – der STANDARD berichtete. Die heurige Opernball-Übertragung erzielte im Teletest die beste Publikums-Beurteilung seit der Erhebung dieser Daten in den 1990er-Jahren. Daran änderte auch ein Mini-Eklat um Moderatorin Mirjam Weichselbraun nichts. Einen Einspieler mit Opernball-Aufnahmen aus den 1980er-Jahren, in dem die damalige ORF-Moderatorin und heutige FPÖ-Politikerin Ursula Stenzel den Sänger Harald Serafin interviewt hatte, kommentierte Weichselbraun mit einer Spitze gegen die Ex-Kollegin: Ich frage mich, was aus der Interviewerin geworden ist. Wahrscheinlich nicht viel. Die Szene des Anstoßes – auf Youtube gestellt von FPÖ-TV Weichselbraun zog damit den Ärger der FPÖ auf sich, und die Freiheitlichen wollen die Opernball-Übertragung nun zum Thema im ORF-Publikumsrat machen. Von einer skandalösen Entgleisung sprach FPÖ-Generalsekretär Herbert Kickl am Freitag. Es stehe der Moderatorin eines öffentlich-rechtlichen Senders nicht zu, vor laufender Kamera und einem Millionenpublikum eine derart abfällige Bemerkung über Dritte zu machen, in diesem Fall über eine hochverdiente langjährige ZiB-Moderatorin, höchst erfolgreiche Politikerin und Landtagsabgeordnete der FPÖ Wien, meinte Kickl. Das steht in krassem Widerspruch zum öffentlich-rechtlichen Auftrag des ORF. Die FPÖ werde der Frage nachgehen, ob es sich um eine spontane Eingebung Weichselbrauns gehandelt habe, denn. Der Verdacht liegt nahe, dass es ein abgekartetes Spiel war und ein früheres Interview Ursula Stenzels mit Harald Serafin nur deshalb eingespielt wurde, um Weichselbraun Gelegenheit für ihre wohlvorbereitete Diffamierung zu bieten, so Kickl. Dort war man unterdessen um Beruhigung bemüht. Trademark der ORF-Moderationen beim Opernball ist ein spielerisch-ironischer Grundton, der dem gesellschaftlichen Höhepunkt des Faschings angemessen ist. Wenn dann im Laufe einer dreistündigen TV-Live-Übertragung bei aller Professionalität eine Pointe einmal nicht richtig aufgeht oder missverständlich ankommt, ist das bedauerlich und selbstverständlich nicht beabsichtigt, erklärte TV-Unterhaltungschef Edgar Böhm gegenüber der APA. Same procedure as every year hieß es unterdessen bei den Lugners. Laut dem Privatsender ATV kam es zwischen Opernball-Gottseibeiuns! Richard Lugner und Frau Cathy in der Ballnacht zum Streit. Die beiden fuhren getrennt nach Hause. Frau Lugner soll sich zu intensiv um ihren Gast Mr. Probz gekümmert haben, unschöne Streitszenen und heftige Wortgefechte waren die Folge. Ob es dieses Mal zur Scheidung reicht oder es sich nur um eine quotenbedingte Inszenierung handelt, zeigt der Sender am Freitag um 19.35 Uhr in seiner Doku-Soap Mörtel am Opernball 2016: Stress am Ball.\n",
      "Features: \n",
      " \tinput_ids: [3, 64, 13944, 14897, 188, 19537, 618, 14381, 243, 6772, 383, 21155, 842, 86, 26375, 243, 20359, 567, 2, 864, 26375, 151, 1422, 20333, 28, 243, 25492, 532, 565, 4429, 151, 4813, 2319, 2, 24347, 280, 2036, 5913, 82, 2036, 10795, 4527, 1287, 42, 39, 14156, 243, 19793, 15677, 2, 246, 5213, 203, 16364, 39, 1483, 26920, 1771, 107, 30, 26375, 243, 9362, 91, 5596, 10030, 1152, 26902, 5982, 99, 2036, 6613, 26942, 1483, 6160, 1372, 4813, 39, 7186, 21, 4332, 243, 2492, 17483, 235, 4632, 86, 10030, 1152, 243, 4253, 50, 26375, 99, 4813, 125, 7972, 259, 2439, 4813, 2495, 1971, 13316, 255, 81, 62, 2036, 8938, 26933, 1483, 2036, 106, 8259, 636, 229, 62, 2036, 4242, 26960, 1483, 4813, 233, 22858, 5810, 8794, 1028, 2, 4]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabel_ids: 7\n",
      "07/17/2019 18:15:27 - INFO - farm.data_handler.processor -   *** Example ***\n",
      "ID: train-4506-0\n",
      "Clear Text: \n",
      " \tlabel: Panorama\n",
      " \ttext: Zweite Wochenhälfte wieder mit Temperaturen jenseits der 30 Grad. Wien – Die Abkühlung war nur eine vorübergehende. Laut Prognose der Zentralanstalt für Meteorologie und Geodynamik (ZAMG) gilt es in den kommenden Tagen zwar noch eine Kaltfront zu durchtauchen, dann meldet sich aber der Sommer zurück. Für die zweite Wochenhälfte sind wieder Temperaturen über 30 Grad angesagt. Die Details: Am Montag überwiegt nördlich des Alpenhauptkammes in den Landesteilen östlich von Salzburg sowie generell am Alpenostrand und im Grazer Becken meist sonniges und trockenes Wetter. Nur vereinzelt zieren ein paar dichtere Wolken den Himmel, die jedoch harmlos bleiben. Im Westen und Süden wechseln kurze sonnige Phasen mit deutlich mehr Wolken. Während es in Osttirol bereits am Vormittag häufig regnet, setzt der Regen sonst erst im Laufe des Nachmittags ein. Der Wind weht schwach bis mäßig, am Alpenostrand und an der föhnigen Alpennordseite lebhaft bis kräftig aus Ost bis Südwest. Die Frühtemperaturen liegen zwischen neun und 18 Grad, die Nachmittagstemperaturen zwischen 23 und 32 Grad, im Südwesten bleibt es kühler mit 18 bis 22 Grad. Am Dienstag hängen bis Mittag im ganzen Land dichte Wolken am Himmel, aus denen häufig Regenschauer niedergehen. Den meisten Niederschlag gibt es südlich des Alpenhauptkammes. In der Folge beginnt jedoch die Wolkendecke aufzulockern und die sonnigen Abschnitte nehmen zu. Am längsten trüb mit Schauern bleibt es in Osttirol und Kärnten. Der Wind kommt schwach bis mäßig, im Osten anfangs lebhaft aus West bis Nord. Die Tiefsttemperaturen betragen elf bis 19 Grad, die Tageshöchsttemperaturen 18 bis 25 Grad. Am Mittwoch startet der Tag stellenweise mit etwas Nebel. Tagsüber scheint aber verbreitet die Sonne und es ziehen meist nur hohe, dünne Schleierwolken über den Himmel. Stärkere Quellwolkenbildung gibt es nur entlang des Alpenhauptkammes und im Südwesten. Hier sind lokale Regenschauer nicht auszuschließen. Der Wind weht generell nur schwach. Die Frühwerte liegen bei acht bis 15 Grad, sie steigen tagsüber auf 21 bis 28 Grad. Viel Sonne sollte es am Donnerstag geben. Zwar ziehen von Westen her im Tagesverlauf einige hohe, dünne Wolkenfelder auf. Diese können den sonnigen Eindruck aber nicht trüben. Der Wind weht schwach bis mäßig aus Südost bis Süd. Von zehn bis Grad in der Früh steigen die Temperaturen auf 26 bis 31 Grad. Auch am Freitag scheint die Sonne in weiten Teilen des Landes nahezu ungetrübt, Quellwolken gibt es nur wenige über dem Alpenhauptkamm. In der Osthälfte ziehen zeitweise noch ein paar hohe Schleierwolken über den Himmel. Der Wind weht schwach bis mäßig aus Südost bis Süd. Die Frühtemperaturen liegen bei elf bis 18 Grad, die Höchsttemperaturen bei 26 bis 33 Grad.\n",
      "Features: \n",
      " \tinput_ids: [3, 15335, 2124, 17451, 525, 114, 14037, 14751, 21, 1144, 6327, 4813, 2319, 2, 125, 14423, 2305, 27, 185, 356, 155, 8608, 26897, 4813, 5126, 11397, 21, 5832, 2816, 142, 21278, 1864, 42, 241, 13606, 4556, 172, 123, 122, 26924, 13898, 5133, 1626, 229, 50, 86, 5649, 3499, 1616, 357, 155, 23708, 8025, 81, 261, 13248, 280, 2036, 670, 23932, 144, 386, 21, 2213, 705, 4813, 864, 30, 2961, 2124, 17451, 287, 525, 14037, 204, 1144, 6327, 3452, 1063, 4813, 125, 10834, 5982, 570, 4141, 10005, 202, 4879, 91, 8913, 2063, 25491, 16, 50, 86, 1168, 6598, 5841, 88, 11054, 545, 11306, 235, 8913, 1268, 2741, 42, 106, 14042, 6, 12764, 2734, 20157, 1865, 42, 10740, 16, 7155, 4813, 3459, 19579, 2892, 444, 39, 4895, 12061, 1031, 4]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabel_ids: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/17/2019 18:15:27 - INFO - farm.data_handler.processor -   *** Example ***\n",
      "ID: train-3657-0\n",
      "Clear Text: \n",
      " \tlabel: Panorama\n",
      " \ttext: Zuvor war von zwei Getöteten berichtet worden – Nun wurden sechs weitere Leichen identifiziert. Mexiko-Stadt – Nach dem versehentlichen Beschuss einer Touristengruppe durch ägyptische Sicherheitskräfte ist die Zahl der dabei getöteten Mexikaner auf acht gestiegen. Das mexikanische Außenministerium erklärte am Dienstag, sechs weitere Leichen seien von Diplomaten vor Ort identifiziert worden. Zuvor war von zwei getöteten, sechs verletzten und sechs noch vermissten Landsleuten die Rede gewesen. Ägyptische Polizisten und Soldaten hatten am Sonntag bei der Verfolgung von islamistischen Kämpfern im Westen des Landes versehentlich einen Konvoi von mexikanischen Touristen beschossen, die in ägyptischer Begleitung waren. Insgesamt befanden sich 14 Mexikaner in der Touristengruppe. Die sechs bei dem Vorfall Verletzten wurden am Dienstag weiter im Krankenhaus behandelt, waren aber nicht in Lebensgefahr. Bei dem Beschuss waren nach Angaben der ägyptischen Behörden insgesamt zwölf Menschen getötet worden. Die mexikanische Außenministerin Claudia Ruiz Massieu reiste am Dienstag nach Kairo. Sie wollte sich dort mit Regierungsvertretern treffen, um Antworten zu den Hintergründen des Vorfalls zu erhalten. Begleitet wurde sie von Angehörigen der mexikanischen Todesopfer.\n",
      "Features: \n",
      " \tinput_ids: [3, 9198, 185, 88, 382, 6090, 6418, 7, 3900, 671, 2, 4692, 468, 1938, 1344, 16569, 17984, 4813, 8766, 243, 560, 2, 326, 128, 7607, 5323, 549, 308, 225, 10736, 2390, 261, 16155, 262, 3503, 4520, 127, 30, 1411, 21, 1340, 7235, 7, 6760, 5548, 115, 2531, 10228, 4813, 295, 14759, 9202, 10392, 660, 4259, 235, 4674, 2036, 1938, 1344, 16569, 1196, 88, 22627, 200, 874, 17984, 671, 4813, 9198, 185, 88, 382, 7235, 7, 2036, 1938, 23088, 42, 1938, 357, 25918, 7, 11514, 15806, 30, 4468, 1396, 4813, 9521, 15099, 1065, 8166, 42, 4200, 1520, 235, 3030, 178, 21, 8930, 88, 8864, 2370, 18772, 26898, 106, 3243, 91, 1168, 7607, 2395, 303, 438, 4723, 26899, 88, 22354, 10736, 824, 3309, 2036, 30, 50, 16155, 532, 19861, 4]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabel_ids: 3\n",
      "07/17/2019 18:15:27 - INFO - farm.data_handler.data_silo -   Loading dev set as a slice of train set\n",
      "07/17/2019 18:15:27 - INFO - farm.data_handler.data_silo -   Took 924 samples out of train set to create dev set (dev split = 0.1)\n",
      "07/17/2019 18:15:27 - INFO - farm.data_handler.data_silo -   Loading test set from: ../data/gnad/test.csv\n",
      "07/17/2019 18:15:34 - INFO - farm.data_handler.processor -   *** Show 3 random examples ***\n",
      "07/17/2019 18:15:34 - INFO - farm.data_handler.processor -   *** Example ***\n",
      "ID: test-209-0\n",
      "Clear Text: \n",
      " \tlabel: Wirtschaft\n",
      " \ttext: Finanzminister erinnert an Unumkehrbarkeit von Währungsunion. Athen – Eine Rückkehr vom Euro zur Drachme würde Griechenland nach Angaben von  Finanzminister Giannis Varoufakis auch vor äußerst praktische Probleme stellen.  Wir haben die Notenpressen zerstört, sagte Varoufakis am Donnerstag im  australischen Radiosender ABC. Im Jahr 2000, ein Jahr vor der Einführung des Euro, war nach seinen Worten  eines der ersten Dinge, die wir tun mussten, alle unsere Notenpressen  loszuwerden – als Teil einer Beteuerung, dass diese Währungsunion unumkehrbar  ist. Zum Drucken der Drachme habe Griechenland somit keine Kapazitäten mehr. Angesichts der festgefahrenen Lage im Schuldenstreit zwischen Griechenland  und seinen internationalen Gläubigern wird über ein Ausscheiden des Landes aus  der Eurozone spekuliert. Am Sonntag will die griechische Regierung die  Bevölkerung in einem Referendum über die Forderungen der Gläubiger abstimmen  lassen. Sie wirbt dabei massiv für ein Nein zu den Vorschlägen.\n",
      "Features: \n",
      " \tinput_ids: [3, 13330, 6446, 104, 234, 107, 801, 3082, 88, 13420, 6219, 4813, 8753, 2, 917, 5268, 275, 918, 252, 6582, 8, 373, 1903, 7119, 188, 2428, 88, 13330, 3945, 13408, 26902, 4975, 1504, 8716, 4824, 26902, 194, 200, 10527, 19051, 5034, 3392, 4813, 655, 474, 30, 10277, 17195, 26898, 6192, 2036, 1267, 4975, 1504, 8716, 4824, 26902, 235, 4632, 106, 13933, 6439, 8198, 23954, 26958, 4813, 346, 203, 2271, 2036, 39, 203, 200, 21, 6165, 91, 918, 2036, 185, 188, 800, 8602, 443, 21, 781, 7760, 2036, 30, 232, 4013, 4657, 2036, 987, 6712, 10277, 17195, 26898, 7066, 271, 5420, 2, 153, 717, 225, 483, 2607, 27, 2036, 221, 620, 13420, 6219, 24378, 801, 351, 127, 4813, 2147, 3548, 7, 21, 6582, 8, 373, 555, 7119, 3361, 4]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabel_ids: 5\n",
      "07/17/2019 18:15:35 - INFO - farm.data_handler.processor -   *** Example ***\n",
      "ID: test-864-0\n",
      "Clear Text: \n",
      " \tlabel: Inland\n",
      " \ttext: Wahl der neuen Landesregierung unter ÖVP-Chef Hermann Schützenhofer. Graz - Am Dienstag trat der neue steiermärkische Landtag zur konstituierenden Sitzung zusammen, um die neue Landesregierung und die Landtagspräsidenten zu wählen. Der scheidende Landeshauptmann Franz Voves (SPÖ) war nicht anwesend, dafür die früheren Landeschefs Josef Krainer und Waltraud Klasnic (beide ÖVP). Bei der Wahl der Landtagspräsidenten gab es keine Einstimmigkeit. Die Grünen verweigerten FPÖ-Chef Gerhard Kurzmann ihre Zustimmung zur Wahl zum Dritten Präsidenten: Wer einen derartig hetzerischen Wahlkampf gegen Minderheiten und Asylsuchende mitzuverantworten habe, dürfe dieses Amt nicht innehaben, so Grün-Abgeordneter Lambert Schönleitner. Die KPÖ erteilte nicht nur Kurzmann, sondern auch der Ersten Landtagspräsidentin Bettina Vollath eine Absage. Begründung des Landtagsabgeordneten Werner Murgg: Es ist keine gute Sitte, jemand zur Präsidentin zu machen, die diesem Landtag nie angehört hat. Manuela Khom (ÖVP) wähle man selbstverständlich, sie habe diesem Hause angehört. Beim dritten Präsidenten gehe man traditionell nicht mit, das Amt solle man abschaffen. Der Grüne Abgeordnete Lambert Schönleitner erklärte: Wir wählen Vollath mit, sie war stets sehr offen in Richtung Opposition, z. B. beim Haushaltsrecht. Selbiges gelte für Manuela Khom (ÖVP). Persönlich habe er nichts gegen Gerhard Kurzmann, man wähle ihn wegen der Politik der FPÖ nicht mit, die Partei habe einen sehr problematischen Wahlkampf geführt, z. B. auf Plakaten Wohnungsbau und Moscheen gegeneinander ausgespielt. Im neuen steirischen Landtag sitzen 15 Abgeordnete der SPÖ, je 14 der ÖVP und Freiheitlichen sowie drei Grüne und zwei Kommunisten. Erstmals war die  Sitzung am Dienstag von Gebärdendolmetscherinnen begleitet. Innerhalb der nächsten eineinhalb Jahre solle es ein nachfrageorientiertes Angebot in dieser Hinsicht geben, hieß es.\n",
      "Features: \n",
      " \tinput_ids: [3, 1401, 21, 1280, 13791, 267, 26318, 243, 3913, 5769, 15393, 8838, 4813, 14042, 243, 570, 4674, 2415, 21, 1234, 3809, 97, 8239, 4824, 1065, 4306, 252, 494, 12678, 3471, 9470, 1037, 2036, 259, 30, 1234, 13791, 42, 30, 16417, 8210, 81, 11900, 4813, 233, 20736, 57, 1168, 26748, 2748, 4087, 10587, 123, 26336, 5133, 185, 149, 20321, 2036, 1760, 30, 4263, 1168, 8386, 26902, 6111, 5795, 1506, 42, 14599, 6118, 26904, 5993, 26902, 14314, 26909, 123, 3296, 26318, 5133, 4813, 467, 21, 1401, 21, 16417, 8210, 1301, 229, 668, 18865, 21258, 25717, 26908, 359, 4813, 125, 5373, 26792, 26898, 64, 13944, 243, 3913, 8003, 3656, 749, 682, 6990, 252, 1401, 260, 8731, 4978, 5982, 1309, 303, 5057, 80, 5726, 15065, 4368, 8966, 383, 19611, 42, 26272, 4]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabel_ids: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/17/2019 18:15:35 - INFO - farm.data_handler.processor -   *** Example ***\n",
      "ID: test-61-0\n",
      "Clear Text: \n",
      " \tlabel: Web\n",
      " \ttext: Name des Nachfolgers von \"sanft & sorgfältig\" wird noch nicht verraten, auch nichts zu den Inhalten. Jan Böhmermann und Olli Schulz starten an diesem Sonntag bei Spotify. Nur drei Tage, nachdem Böhmermanns TV-Show Neo Magazin Royal bei ZDFneo am Donnerstag, 12. Mai, wieder zu sehen ist, soll das erste neue Podcast des Duos zu hören sein. Das teilte der Streamingdienst am Montag in seinem Blog mit. Zum Namen der neuen Show nach dem Ende der bisherigen Show sanft & sorgfältig hieß es lapidar: Das dürfen wir Euch noch nicht verraten. Auch zu Inhalten sei noch nichts mitzuteilen, sagte eine Sprecherin. Spotify ist weltweiter Marktführer unter den Streamingdiensten. Beim Streaming werden Musikstücke oder andere Audiobeiträge direkt aus dem Netz abgespielt. Olli Schulz und Jan Böhmermann hatten ihre Sonntagsshow sanft & sorgfältig beim RBB-Sender Radioeins. Ende April hatte das Duo angekündigt, sanft & sorgfältig nicht fortsetzen zu wollen. Spotify spielt mit dem Namen der bisherigen Show und präsentiert auf seinem Blog eine Reihe von Plakaten, die für den neuen Podcast werben sollen: Abgefuckt & Anspruchslos etwa gab es schon länger, Maskulin & Mariniert, Potent & Preisgekrönt sowie Vegan & Verschmust sind neu hinzugekommen.\n",
      "Features: \n",
      " \tinput_ids: [3, 3504, 91, 4076, 26902, 88, 151, 8485, 136, 2461, 24222, 151, 292, 357, 149, 21880, 2036, 194, 2013, 81, 86, 13940, 26898, 4813, 4802, 22695, 6, 749, 42, 1624, 3299, 12476, 13179, 104, 798, 3030, 178, 276, 237, 778, 26951, 4813, 3459, 678, 2908, 2036, 3135, 22695, 6, 7099, 4332, 243, 7491, 929, 26910, 11263, 8783, 178, 9168, 175, 26910, 235, 4632, 2036, 810, 4813, 1200, 2036, 525, 81, 2265, 127, 2036, 459, 93, 1139, 1234, 11024, 17004, 91, 18506, 26902, 81, 7734, 167, 4813, 295, 5751, 21, 2218, 24742, 2068, 235, 4141, 50, 813, 17812, 114, 4813, 2147, 1646, 21, 1280, 7491, 188, 128, 926, 21, 4670, 7491, 8485, 136, 2461, 24222, 5453, 229, 2094, 26920, 11372, 5982, 295, 4030, 232, 8408, 8, 357, 149, 4]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabel_ids: 0\n",
      "07/17/2019 18:15:35 - INFO - farm.data_handler.data_silo -   Examples in train: 8320\n",
      "07/17/2019 18:15:35 - INFO - farm.data_handler.data_silo -   Examples in dev  : 924\n",
      "07/17/2019 18:15:35 - INFO - farm.data_handler.data_silo -   Examples in test : 1027\n",
      "07/17/2019 18:15:35 - INFO - farm.data_handler.data_silo -   Using class weights: [0.6733025815327345, 0.9394760614272809, 0.7602339181286549, 0.6878306878306878, 1.966903073286052, 0.8080808080808081, 2.154882154882155, 1.7247097844112769, 1.121898597626753]\n"
     ]
    }
   ],
   "source": [
    "# Pipeline should also contain metric\n",
    "data_silo = DataSilo(\n",
    "    processor=processor,\n",
    "    batch_size=32,\n",
    "    distributed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a distinction between prediction head and language model. Here we initialize. TextClassifiction head is deep FF network\n",
    "\n",
    "BERT is Google's model. Can based on HuggingFace. Can load from dir or download.\n",
    "\n",
    "Explain params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/17/2019 18:19:13 - INFO - farm.modeling.language_model -   loading archive file s3://int-models-bert/bert-base-cased-de-2b-end/bert-base-cased-de-2b-end.tar.gz from cache at /Users/deepset/.cache/torch/farm/9c04dc7fe652b18e117a3bcfbbd50a46dd97dcce1b27f4689c47c52fbf0ebf77.5d8643be67c1cdea6a3daad77fcc21f22aaca376cc4bffa9152d4260c4285410\n",
      "07/17/2019 18:19:13 - INFO - farm.modeling.language_model -   extracting archive file /Users/deepset/.cache/torch/farm/9c04dc7fe652b18e117a3bcfbbd50a46dd97dcce1b27f4689c47c52fbf0ebf77.5d8643be67c1cdea6a3daad77fcc21f22aaca376cc4bffa9152d4260c4285410 to temp dir /var/folders/9y/kg7mpp0947l5n87j11ff64200000gp/T/tmp793j2knm\n",
      "07/17/2019 18:19:19 - INFO - farm.modeling.language_model -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "07/17/2019 18:19:21 - INFO - farm.modeling.language_model -   Automatically detected language from language model name: german\n"
     ]
    }
   ],
   "source": [
    "prediction_head = TextClassificationHead(layer_dims=[768, 9])\n",
    "language_model = Bert.load(\"bert-base-german-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Core feature of this framework is the ability to mix and match language models and prediction heads. Allows for handling different tasks with the one language model. Language model adaptation for better downstream task performance. Even can do joint training using multiple prediction heads.\n",
    "\n",
    "language model and prediction heads are combined in the AdaptiveModel\n",
    "\n",
    "Explain a few params\n",
    "\n",
    "## HAVE DIAGRAM??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AdaptiveModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4d156cabe527>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO where are balance class weights?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model = AdaptiveModel(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlanguage_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlanguage_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprediction_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprediction_head\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0membeds_dropout_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AdaptiveModel' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO where are balance class weights?\n",
    "model = AdaptiveModel(\n",
    "    language_model=language_model,\n",
    "    prediction_heads=[prediction_head],\n",
    "    embeds_dropout_prob=0.1,\n",
    "    lm_output_types=[\"per_sequence\"],\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can initialize a Bert Adam (?) optimizer using the following. Here you can set learning rate\n",
    "Dependency on n_examples, batch_size, n_epochs? Are these defined elsewhere?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'initialize_optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f9d744406ad5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Init optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m optimizer, warmup_linear = initialize_optimizer(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwarmup_proportion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'initialize_optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Init optimizer\n",
    "optimizer, warmup_linear = initialize_optimizer(\n",
    "    model=model,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_proportion=0.1,\n",
    "    n_examples=data_silo.n_samples(\"train\"),\n",
    "    batch_size=16,\n",
    "    n_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop handled by this. Will also deal evaluating during training and also evaluating on test set so long as these files are defined in Processor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    optimizer=optimizer,\n",
    "    data_silo=data_silo,\n",
    "    epochs=10,\n",
    "    n_gpu=1,\n",
    "    warmup_linear=warmup_linear,\n",
    "    evaluate_every=100,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Switch to NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we do this? Get them to go into code? Or just mix components?\n",
    "\n",
    "See the power of transfer learning\n",
    "\n",
    "Perform new task\n",
    "Use same language model\n",
    "but different prediction head\n",
    "also different data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from farm.data_handler.processor import CONLLProcessor\n",
    "from farm.modeling.prediction_head import TokenClassificationHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = CONLLProcessor(tokenizer=tokenizer,\n",
    "                           max_seq_len=128,\n",
    "                           data_dir=\"../data/conll03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_head = TokenClassificationHead(layer_dims=[768, 9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to integrate these into the other components\n",
    "\n",
    "New datasilo\n",
    "\n",
    "new adaptive model\n",
    "\n",
    "This code is exactly the same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_silo = DataSilo(\n",
    "    processor=processor,\n",
    "    batch_size=32,\n",
    "    distributed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO where are balance class weights?\n",
    "model = AdaptiveModel(\n",
    "    language_model=language_model,\n",
    "    prediction_heads=[prediction_head],\n",
    "    embeds_dropout_prob=0.1,\n",
    "    lm_output_types=[\"per_sequence\"],\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer, warmup_linear = initialize_optimizer(\n",
    "    model=model,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_proportion=0.1,\n",
    "    n_examples=data_silo.n_samples(\"train\"),\n",
    "    batch_size=16,\n",
    "    n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    optimizer=optimizer,\n",
    "    data_silo=data_silo,\n",
    "    epochs=10,\n",
    "    n_gpu=1,\n",
    "    warmup_linear=warmup_linear,\n",
    "    evaluate_every=100,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this too confusing? Hard to keep track of what's persisting in notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we should have a fn that takes these components as args. Can then just feed new dataprocessor and prediction head and it will initialize a new experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say how processor can be totally over written"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
